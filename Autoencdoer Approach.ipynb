{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from PIL import Image\n",
    "from scipy.misc import imsave\n",
    "import glob\n",
    "from os.path import basename\n",
    "from scipy.misc import imresize\n",
    "\n",
    "\n",
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, Input, Dense,Flatten,LeakyReLU\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(K.backend())\n",
    "\n",
    "from image_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_data, augmented_train_label = load_augmented_data(\"./augmented_data/\", \"train\")\n",
    "augmented_validation_data, augmented_validation_label = load_augmented_data(\"./augmented_data/\", \"val\")\n",
    "augmented_test_data, augmented_test_label = load_augmented_data(\"./augmented_data/\", \"test\")\n",
    "\n",
    "partition_dict, labels_dict = get_generator_dicts(\"./augmented_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, path, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=3,\n",
    "                  shuffle=True, fully_convolutional = True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.path = path\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, 2), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = imresize(np.array(Image.open(self.path + ID + '.png')), resize_factor)/255\n",
    "            \n",
    "\n",
    "            # Store class\n",
    "            y[i,0], y[i,1] = self.labels[ID]\n",
    "            \n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir='./logs/regression', histogram_freq=2, batch_size=32, write_graph=True, write_grads=True, write_images=True)\n",
    "cpCallBack = ModelCheckpoint('./checkpoints/regression/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=3)\n",
    "esCallBack = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(augmented_train_data[0].shape[0], augmented_train_data[0].shape[1], 3))\n",
    "\n",
    "x = Conv2D(3, (1, 1), padding='same', use_bias=False)(input_img)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Conv2D(8, (3, 3), padding='same', use_bias=False)(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Conv2D(8, (3, 3), padding='same', use_bias=False)(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Conv2D(1, (1, 1), padding='same', use_bias=False)(x)\n",
    "x = LeakyReLU(alpha=0.3)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(8, activation='relu', use_bias=False)(x)\n",
    "\n",
    "\n",
    "output = Dense(2, use_bias=False)(x)\n",
    "\n",
    "model = Model(inputs=input_img, outputs=output)\n",
    "\n",
    "from keras import optimizers\n",
    "#sgd = optimizers.SGD(lr=1e-11, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1e-9)\n",
    "model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "\n",
    "#tbCallBack.set_model(model)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (augmented_train_data[0].shape[0],augmented_train_data[0].shape[1]),\n",
    "          'batch_size': 32,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "training_generator = DataGenerator(\"./augmented_data/data/\", partition_dict['train'], labels_dict, **params)\n",
    "validation_generator = DataGenerator(\"./augmented_data/data/\", partition_dict['val'], labels_dict, **params)\n",
    "\n",
    "#history = model.fit_generator(generator=training_generator, validation_data=[augmented_validation_data, augmented_validation_label], epochs=3, callbacks=[cpCallBack, esCallBack])\n",
    "\n",
    "\n",
    "history = model.fit(augmented_train_data_resized, augmented_train_label, validation_data=[augmented_validation_data_resized, augmented_validation_label] ,epochs=1000, batch_size=32, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(augmented_train_data_resized[:10])\n",
    "print(predictions)\n",
    "for i, pred in enumerate(predictions):\n",
    "    plot_with_label(augmented_train_data_resized[i], pred[0], pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(augmented_validation_data_resized)\n",
    "for i, pred in enumerate(predictions):\n",
    "    plot_with_label(augmented_validation_data_resized[i], pred[0], pred[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
